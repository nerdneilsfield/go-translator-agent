# 示例配置文件 - 展示新的步骤集系统
# 这个配置展示了如何使用新的灵活步骤集系统，支持混合使用不同的翻译提供商

# 基本语言设置
source_lang: English
target_lang: Chinese
country: China

# 默认模型名称
default_model_name: gpt-3.5-turbo

# 模型配置
models:
  # OpenAI 模型
  gpt-3.5-turbo:
    name: gpt-3.5-turbo
    model_id: gpt-3.5-turbo
    api_type: openai
    base_url: https://api.openai.com/v1
    key: ${OPENAI_API_KEY}
    max_output_tokens: 4096
    max_input_tokens: 4096
    temperature: 0.7
    input_token_price: 0.5
    output_token_price: 1.5
    price_unit: USD
    is_reasoning: false

  gpt-4:
    name: gpt-4
    model_id: gpt-4
    api_type: openai
    base_url: https://api.openai.com/v1
    key: ${OPENAI_API_KEY}
    max_output_tokens: 8192
    max_input_tokens: 8192
    temperature: 0.7
    input_token_price: 30
    output_token_price: 60
    price_unit: USD
    is_reasoning: false

  # OpenAI 推理模型
  o1-preview:
    name: o1-preview
    model_id: o1-preview
    api_type: openai
    base_url: https://api.openai.com/v1
    key: ${OPENAI_API_KEY}
    max_output_tokens: 32768
    max_input_tokens: 128000
    temperature: 1
    input_token_price: 15
    output_token_price: 60
    price_unit: USD
    is_reasoning: true
    # OpenAI o1 的推理过程已经被隐藏，API 不会返回

  o1-mini:
    name: o1-mini
    model_id: o1-mini
    api_type: openai
    base_url: https://api.openai.com/v1
    key: ${OPENAI_API_KEY}
    max_output_tokens: 65536
    max_input_tokens: 128000
    temperature: 1
    input_token_price: 3
    output_token_price: 12
    price_unit: USD
    is_reasoning: true

  # DeepSeek 推理模型
  deepseek-r1:
    name: deepseek-r1
    model_id: deepseek-r1
    api_type: openai
    base_url: https://api.deepseek.com/v1
    key: ${DEEPSEEK_API_KEY}
    max_output_tokens: 8192
    max_input_tokens: 32768
    temperature: 0.7
    input_token_price: 0.14
    output_token_price: 2.19
    price_unit: USD
    is_reasoning: true
    reasoning_tags: ["<think>", "</think>"]

  # QwQ 推理模型
  qwq-32b:
    name: qwq-32b
    model_id: qwq-32b-preview
    api_type: openai
    base_url: ${QWQ_API_BASE}  # 需要配置具体的 API 端点
    key: ${QWQ_API_KEY}
    max_output_tokens: 32768
    max_input_tokens: 32768
    temperature: 0.7
    is_reasoning: true
    reasoning_tags: ["<think>", "</think>"]

  # DeepL 配置
  deepl:
    name: deepl
    model_id: deepl
    api_type: deepl
    base_url: https://api.deepl.com/v2
    key: ${DEEPL_API_KEY}

  # DeepLX 配置（免费）
  deeplx:
    name: deeplx
    model_id: deeplx
    api_type: deeplx
    base_url: http://localhost:1188
    key: ""  # DeepLX 不需要密钥

  # Google Translate 配置
  google-translate:
    name: google-translate
    model_id: google-translate
    api_type: google
    key: ${GOOGLE_API_KEY}

  # LibreTranslate 配置（开源）
  libretranslate:
    name: libretranslate
    model_id: libretranslate
    api_type: libretranslate
    base_url: https://libretranslate.com
    key: ${LIBRETRANSLATE_API_KEY}  # 某些实例可能需要

# 新格式的步骤集配置
step_sets_v2:
  # 基础配置 - 使用单一 LLM
  basic:
    id: basic
    name: 基本翻译
    description: 使用单一模型的三步翻译过程
    steps:
      - name: initial_translation
        provider: openai
        model_name: gpt-3.5-turbo
        temperature: 0.5
        max_tokens: 4096
        prompt: |
          Translate the following {{source}} text to {{target}}. 
          Maintain the original meaning, tone, and style:
          
          {{text}}
        system_role: You are a professional translator.

      - name: reflection
        provider: openai
        model_name: gpt-3.5-turbo
        temperature: 0.3
        max_tokens: 2048
        prompt: |
          Review this translation and identify any issues:
          
          Original: {{original_text}}
          Translation: {{translation}}
          
          Provide specific feedback.
        system_role: You are a translation quality reviewer.

      - name: improvement
        provider: openai
        model_name: gpt-3.5-turbo
        temperature: 0.5
        max_tokens: 4096
        prompt: |
          Improve this translation based on the feedback:
          
          Original: {{original_text}}
          Translation: {{translation}}
          Feedback: {{feedback}}
          
          Provide an improved translation.
        system_role: You are a professional translator focusing on quality improvement.

    fast_mode_threshold: 300

  # 混合模式 - 结合专业翻译服务和 AI
  mixed_professional:
    id: mixed_professional
    name: 混合专业翻译
    description: 使用 DeepL + GPT-4 的组合，获得最佳翻译效果
    steps:
      # 第一步：使用 DeepL 获得专业翻译
      - name: deepl_translation
        provider: deepl
        model_name: deepl
        temperature: 0
        prompt: "{{text}}"  # DeepL 只需要原文

      # 第二步：使用 GPT-4 评估 DeepL 的翻译
      - name: ai_review
        provider: openai
        model_name: gpt-4
        temperature: 0.2
        max_tokens: 3000
        prompt: |
          作为一位精通{{source}}和{{target}}的语言专家，请评估这个由 DeepL 生成的翻译：
          
          原文（{{source}}）：
          {{original_text}}
          
          DeepL 翻译（{{target}}）：
          {{deepl_translation}}
          
          请从以下几个方面进行评估：
          1. 准确性：翻译是否准确传达了原文的含义？
          2. 流畅性：译文在{{target}}中是否自然流畅？
          3. 文化适应性：是否考虑了文化差异？
          4. 专业术语：专业术语的翻译是否恰当？
          
          如果有任何问题，请提供具体的改进建议。
        system_role: 你是一位资深的翻译评论家，精通{{source}}和{{target}}两种语言。

      # 第三步：根据评估结果优化翻译
      - name: final_polish
        provider: openai
        model_name: gpt-4
        temperature: 0.3
        max_tokens: 4096
        prompt: |
          基于以下信息，提供最终的优化翻译：
          
          原文：{{original_text}}
          DeepL 翻译：{{deepl_translation}}
          评估反馈：{{ai_review}}
          
          请综合 DeepL 的翻译和 AI 的反馈，生成一个更加准确、流畅的{{target}}翻译。
          保持原文的语气和风格，同时确保符合{{target}}的表达习惯。
        system_role: 你是一位专业的{{target}}编辑，负责润色和完善翻译。

    fast_mode_threshold: 500

  # 多翻译引擎对比模式
  multi_engine_comparison:
    id: multi_engine_comparison
    name: 多引擎对比翻译
    description: 使用多个翻译引擎，通过 AI 选择和综合最佳结果
    steps:
      # 并行使用多个翻译引擎
      - name: deepl_translation
        provider: deepl
        model_name: deepl
        temperature: 0
        prompt: "{{text}}"

      - name: google_translation
        provider: google
        model_name: google-translate
        temperature: 0
        prompt: "{{text}}"

      - name: deeplx_translation
        provider: deeplx
        model_name: deeplx
        temperature: 0
        prompt: "{{text}}"

      # AI 综合评估
      - name: ai_synthesis
        provider: openai
        model_name: gpt-4
        temperature: 0.2
        max_tokens: 4096
        prompt: |
          请分析以下三个翻译引擎的结果，并生成一个综合最优的翻译：
          
          原文（{{source}}）：
          {{original_text}}
          
          翻译结果：
          1. DeepL: {{deepl_translation}}
          2. Google: {{google_translation}}
          3. DeepLX: {{deeplx_translation}}
          
          请：
          1. 比较三个翻译的优缺点
          2. 选择最准确的部分
          3. 修正明显的错误
          4. 生成一个综合最优的{{target}}翻译
          
          最终翻译应该自然、准确、符合{{target}}的表达习惯。
        system_role: 你是一位翻译专家，精通对比分析不同翻译结果。

    fast_mode_threshold: 1000

  # 快速模式 - 仅使用专业翻译服务
  fast_professional:
    id: fast_professional
    name: 快速专业翻译
    description: 仅使用 DeepL，适合需要快速获得高质量翻译的场景
    steps:
      - name: translation
        provider: deepl
        model_name: deepl
        temperature: 0
        prompt: "{{text}}"
    fast_mode_threshold: 10000

  # 免费模式 - 使用开源/免费服务
  free_mode:
    id: free_mode
    name: 免费翻译模式
    description: 使用免费的翻译服务
    steps:
      - name: translation
        provider: libretranslate
        model_name: libretranslate
        temperature: 0
        prompt: "{{text}}"
      
      # 可选：使用本地 LLM 进行优化
      - name: local_improvement
        provider: ollama
        model_name: llama2
        temperature: 0.3
        max_tokens: 4096
        prompt: |
          请优化这个从{{source}}到{{target}}的翻译：
          
          原文：{{original_text}}
          翻译：{{translation}}
          
          使译文更加自然流畅。
        system_role: 你是一位翻译编辑。

    fast_mode_threshold: 5000

# 激活的步骤集
active_step_set: mixed_professional

# 其他配置
max_tokens_per_chunk: 2000
cache_dir: ~/.translator-cache
use_cache: true
debug: false
concurrency: 4
translation_timeout: 300

# 后处理选项
post_process_markdown: true
fix_math_formulas: true
fix_table_format: true
fix_mixed_content: true

  # 推理模型深度翻译
  reasoning_deep:
    id: reasoning_deep
    name: 推理模型深度翻译
    description: 使用推理模型进行深度思考的高质量翻译
    steps:
      # 使用 DeepSeek R1 进行初步翻译
      - name: reasoning_translation
        provider: openai
        model_name: deepseek-r1
        temperature: 0.3
        max_tokens: 8192
        prompt: |
          请将以下{{source}}文本翻译为{{target}}。
          
          请注意：
          1. 保持原文的含义、语气和风格
          2. 确保专业术语的准确性
          3. 考虑文化差异和习惯表达
          4. 保持译文的流畅性和自然性
          
          原文：
          {{text}}
        system_role: 你是一位专业的{{source}}到{{target}}翻译专家。

      # 使用 GPT-4 进行评估（不会看到推理过程）
      - name: quality_review
        provider: openai
        model_name: gpt-4
        temperature: 0.2
        max_tokens: 2048
        prompt: |
          请评估这个从{{source}}到{{target}}的翻译质量：
          
          原文：
          {{original_text}}
          
          译文：
          {{reasoning_translation}}
          
          请从以下方面进行评估：
          1. 准确性：是否准确传达了原文含义
          2. 流畅性：译文是否自然流畅
          3. 专业性：术语翻译是否准确
          4. 文化适应：是否符合目标语言文化
          
          如果有问题，请提供具体的改进建议。
        system_role: 你是一位资深的翻译质量评估专家。

      # 使用 o1-mini 进行最终优化
      - name: final_optimization
        provider: openai
        model_name: o1-mini
        temperature: 0.3
        max_tokens: 8192
        prompt: |
          基于评估反馈，请对翻译进行最终优化：
          
          原文：{{original_text}}
          当前译文：{{reasoning_translation}}
          评估反馈：{{quality_review}}
          
          请提供一个经过优化的最终译文。
        system_role: 你是一位{{target}}语言母语者和专业编辑。

    fast_mode_threshold: 100  # 推理模型需要更多时间，所以设置较低的阈值