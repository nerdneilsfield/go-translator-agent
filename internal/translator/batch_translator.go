package translator

import (
	"context"
	"fmt"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/dlclark/regexp2"
	"github.com/nerdneilsfield/go-translator-agent/internal/document"
	"github.com/nerdneilsfield/go-translator-agent/pkg/providers/stats"
	"github.com/nerdneilsfield/go-translator-agent/pkg/translation"
	"go.uber.org/zap"
)

// BatchTranslator å®ç°Translatoræ¥å£ï¼Œè´Ÿè´£èŠ‚ç‚¹åˆ†ç»„å’Œå¹¶è¡Œç¿»è¯‘
type BatchTranslator struct {
	config             TranslatorConfig
	translationService translation.Service
	logger             *zap.Logger
	preserveManager    *translation.PreserveManager
	smartSplitter      *translation.SmartNodeSplitter // æ™ºèƒ½èŠ‚ç‚¹åˆ†å‰²å™¨
	statsManager       *stats.StatsManager            // ç»Ÿè®¡ç®¡ç†å™¨

	// è¯¦ç»†ç¿»è¯‘è¿‡ç¨‹è·Ÿè¸ª
	translationRounds []*TranslationRoundResult // æ¯è½®ç¿»è¯‘çš„è¯¦ç»†ç»“æœ
	mu                sync.Mutex                // ä¿æŠ¤translationRoundsçš„å¹¶å‘è®¿é—®

	// è¿›åº¦å›è°ƒ
	progressCallback ProgressCallback // è¿›åº¦å›è°ƒå‡½æ•°
}

// NewBatchTranslator åˆ›å»ºæ‰¹é‡ç¿»è¯‘å™¨
func NewBatchTranslator(cfg TranslatorConfig, service translation.Service, logger *zap.Logger, statsManager *stats.StatsManager) *BatchTranslator {
	return &BatchTranslator{
		config:             cfg,
		translationService: service,
		logger:             logger,
		preserveManager:    translation.NewPreserveManager(translation.DefaultPreserveConfig),
		smartSplitter:      translation.NewSmartNodeSplitter(cfg.SmartSplitter, logger),
		statsManager:       statsManager,
		translationRounds:  make([]*TranslationRoundResult, 0),
	}
}

// SetProgressCallback è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°
func (bt *BatchTranslator) SetProgressCallback(callback ProgressCallback) {
	bt.mu.Lock()
	defer bt.mu.Unlock()
	bt.progressCallback = callback
}

// callProgressCallback å®‰å…¨åœ°è°ƒç”¨è¿›åº¦å›è°ƒ
func (bt *BatchTranslator) callProgressCallback(completed, total int, message string) {
	bt.mu.Lock()
	callback := bt.progressCallback
	bt.mu.Unlock()

	if callback != nil {
		callback(completed, total, message)
	}
}

// TranslateNodes ç¿»è¯‘æ‰€æœ‰èŠ‚ç‚¹ï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼ŒåŒ…å«å¤±è´¥é‡è¯•ï¼‰
func (bt *BatchTranslator) TranslateNodes(ctx context.Context, nodes []*document.NodeInfo) error {
	// é‡ç½®ç¿»è¯‘è½®æ¬¡è®°å½•
	bt.mu.Lock()
	bt.translationRounds = make([]*TranslationRoundResult, 0)
	bt.mu.Unlock()

	// æ‰¹é‡ç¿»è¯‘æ‰€æœ‰èŠ‚ç‚¹
	bt.logger.Info("starting batch translation", zap.Int("totalNodes", len(nodes)))

	// ç¬¬ä¸€è½®ï¼šåˆ†ç»„ç¿»è¯‘æ‰€æœ‰èŠ‚ç‚¹
	groups := bt.groupNodes(nodes)
	bt.logger.Debug("initial grouping for translation",
		zap.Int("totalGroups", len(groups)),
		zap.Int("concurrency", bt.config.Concurrency))

	// å¹¶è¡Œå¤„ç†ç¬¬ä¸€è½®ç¿»è¯‘
	initialRoundStart := time.Now()
	bt.callProgressCallback(0, len(nodes), "ç¬¬1è½®ï¼šåˆå§‹ç¿»è¯‘")
	bt.processGroups(ctx, groups)
	initialRoundDuration := time.Since(initialRoundStart)

	// ç»Ÿè®¡ç¬¬ä¸€è½®æˆåŠŸçš„èŠ‚ç‚¹æ•°
	successCount := 0
	for _, node := range nodes {
		if node.Status == document.NodeStatusSuccess {
			successCount++
		}
	}
	bt.callProgressCallback(successCount, len(nodes), fmt.Sprintf("ç¬¬1è½®å®Œæˆï¼šæˆåŠŸ %d/%d", successCount, len(nodes)))

	// è®°å½•ç¬¬ä¸€è½®ç¿»è¯‘ç»“æœ
	bt.recordTranslationRound(1, "initial", len(nodes), nodes, initialRoundDuration)

	// æ£€æŸ¥æ˜¯å¦å¯ç”¨å¤±è´¥é‡è¯•åŠŸèƒ½
	if !bt.config.RetryOnFailure {
		bt.logger.Info("retry disabled by configuration",
			zap.String("retryOnFailure", "false"))

		// ç»Ÿè®¡æœ€ç»ˆç»“æœä½†ä¸é‡è¯•
		successCount := 0
		failedCount := 0
		for _, node := range nodes {
			if node.Status == document.NodeStatusSuccess {
				successCount++
			} else {
				failedCount++
			}
		}

		bt.logger.Info("translation completed without retry",
			zap.Int("completed", successCount),
			zap.Int("failed", failedCount),
			zap.Int("total", len(nodes)),
			zap.Float64("progress", float64(successCount)/float64(len(nodes))*100))

		return nil
	}

	// æ”¶é›†å¤±è´¥èŠ‚ç‚¹å¹¶è¿›è¡Œé‡è¯•
	maxRetries := bt.config.MaxRetries
	if maxRetries <= 0 {
		maxRetries = 3
	}

	// ç»Ÿè®¡åˆå§‹ç¿»è¯‘ç»“æœ
	initialSuccessCount := 0
	initialFailedCount := 0
	for _, node := range nodes {
		if node.Status == document.NodeStatusSuccess {
			initialSuccessCount++
		} else {
			initialFailedCount++
		}
	}

	bt.logger.Info("initial translation round completed",
		zap.Int("successful", initialSuccessCount),
		zap.Int("failed", initialFailedCount),
		zap.Int("total", len(nodes)),
		zap.Float64("successRate", float64(initialSuccessCount)/float64(len(nodes))*100))

	bt.logger.Info("file-level retry mechanism enabled",
		zap.Int("maxRetries", maxRetries),
		zap.Bool("retryOnFailure", bt.config.RetryOnFailure))

	// ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„èŠ‚ç‚¹ï¼Œé¿å…æ— é™é€’å½’
	processedNodes := make(map[int]bool)
	for _, node := range nodes {
		if node.Status == document.NodeStatusSuccess {
			processedNodes[node.ID] = true
		}
	}

	// é‡è¯•å¾ªç¯
	for retry := 1; retry <= maxRetries; retry++ {
		// æ”¶é›†å¤±è´¥èŠ‚ç‚¹
		failedNodes := bt.collectFailedNodes(nodes)
		if len(failedNodes) == 0 {
			break
		}

		// æ£€æŸ¥æ˜¯å¦æœ‰å¯é‡è¯•çš„å¤±è´¥èŠ‚ç‚¹
		retryableNodes := 0
		nonRetryableNodes := 0
		for _, node := range failedNodes {
			if node.Error != nil {
				if transErr, ok := node.Error.(*translation.TranslationError); ok {
					if transErr.IsRetryable() {
						retryableNodes++
					} else {
						nonRetryableNodes++
					}
				} else {
					// éTranslationErroré»˜è®¤ä½œä¸ºå¯é‡è¯•å¤„ç†
					retryableNodes++
				}
			} else {
				retryableNodes++
			}
		}

		// å¦‚æœæ²¡æœ‰å¯é‡è¯•çš„èŠ‚ç‚¹ï¼Œåœæ­¢é‡è¯•
		if retryableNodes == 0 {
			bt.logger.Warn("no retryable nodes found, stopping retry",
				zap.Int("retryRound", retry),
				zap.Int("totalFailedNodes", len(failedNodes)),
				zap.Int("nonRetryableNodes", nonRetryableNodes),
				zap.String("reason", "all failed nodes have non-retryable errors"))
			break
		}

		bt.logger.Info("retryable nodes analysis",
			zap.Int("retryRound", retry),
			zap.Int("totalFailedNodes", len(failedNodes)),
			zap.Int("retryableNodes", retryableNodes),
			zap.Int("nonRetryableNodes", nonRetryableNodes))

		// ä½¿ç”¨INFOçº§åˆ«è®°å½•é‡è¯•å¼€å§‹ä¿¡æ¯
		bt.logger.Info("starting retry for failed nodes",
			zap.Int("retryRound", retry),
			zap.Int("maxRetries", maxRetries),
			zap.Int("failedNodes", len(failedNodes)))

		// é€šçŸ¥å¼€å§‹é‡è¯•
		bt.callProgressCallback(0, len(failedNodes), fmt.Sprintf("ç¬¬%dè½®ï¼šé‡è¯• %d ä¸ªå¤±è´¥èŠ‚ç‚¹", retry+1, len(failedNodes)))

		bt.logger.Debug("collecting failed nodes for retry details",
			zap.Int("retryRound", retry),
			zap.Int("failedNodes", len(failedNodes)))

		// ä¸ºå¤±è´¥èŠ‚ç‚¹æ·»åŠ ä¸Šä¸‹æ–‡å¹¶é‡æ–°åˆ†ç»„
		retryGroups := bt.groupFailedNodesWithContext(nodes, failedNodes, processedNodes)

		if len(retryGroups) == 0 {
			bt.logger.Warn("no retry groups created, stopping retry",
				zap.Int("retryRound", retry),
				zap.Int("failedNodes", len(failedNodes)),
				zap.String("reason", "failed to create retry groups with context"))
			break
		}

		totalRetryNodes := 0
		for _, group := range retryGroups {
			totalRetryNodes += len(group.Nodes)
		}

		bt.logger.Debug("retry grouping with context",
			zap.Int("retryRound", retry),
			zap.Int("failedNodes", len(failedNodes)),
			zap.Int("retryGroups", len(retryGroups)),
			zap.Int("totalNodesWithContext", totalRetryNodes))

		// å¹¶è¡Œå¤„ç†é‡è¯•ç»„
		retryRoundStart := time.Now()
		bt.processGroups(ctx, retryGroups)
		retryRoundDuration := time.Since(retryRoundStart)

		// è®°å½•é‡è¯•è½®æ¬¡ç»“æœ
		bt.recordTranslationRound(retry+1, "retry", len(failedNodes), failedNodes, retryRoundDuration)

		// ç»Ÿè®¡é‡è¯•ç»“æœ
		retrySuccessCount := 0
		retryFailedCount := 0
		for _, failed := range failedNodes {
			if failed.Status == document.NodeStatusSuccess {
				retrySuccessCount++
			} else {
				retryFailedCount++
			}
		}

		// è®°å½•é‡è¯•ç»“æœ
		bt.logger.Info("retry round completed",
			zap.Int("retryRound", retry),
			zap.Int("originalFailedNodes", len(failedNodes)),
			zap.Int("nowSuccessful", retrySuccessCount),
			zap.Int("stillFailed", retryFailedCount))

		// æ›´æ–°è¿›åº¦ï¼šè®¡ç®—æ€»çš„æˆåŠŸèŠ‚ç‚¹æ•°
		totalSuccessCount := 0
		for _, node := range nodes {
			if node.Status == document.NodeStatusSuccess {
				totalSuccessCount++
			}
		}
		bt.callProgressCallback(totalSuccessCount, len(nodes),
			fmt.Sprintf("ç¬¬%dè½®å®Œæˆï¼šæœ¬è½®æˆåŠŸ %dï¼Œæ€»æˆåŠŸ %d/%d", retry+1, retrySuccessCount, totalSuccessCount, len(nodes)))

		// æ›´æ–°å·²å¤„ç†èŠ‚ç‚¹é›†åˆ
		for _, node := range nodes {
			if node.Status == document.NodeStatusSuccess && !processedNodes[node.ID] {
				processedNodes[node.ID] = true
			}
		}
	}

	// è®°å½•æœ€ç»ˆç»Ÿè®¡
	successCount = 0
	failedCount := 0
	for _, node := range nodes {
		if node.Status == document.NodeStatusSuccess {
			successCount++
		} else {
			failedCount++
		}
	}

	// è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
	progressPercent := float64(successCount) / float64(len(nodes)) * 100

	// æœ€ç»ˆè¿›åº¦æ›´æ–°
	if failedCount == 0 {
		bt.callProgressCallback(successCount, len(nodes), "ç¿»è¯‘å®Œæˆï¼šå…¨éƒ¨æˆåŠŸ")
	} else {
		bt.callProgressCallback(successCount, len(nodes), fmt.Sprintf("ç¿»è¯‘å®Œæˆï¼š%d æˆåŠŸï¼Œ%d å¤±è´¥", successCount, failedCount))
	}

	// ä½¿ç”¨ INFO çº§åˆ«æ˜¾ç¤ºç¿»è¯‘å®Œæˆä¿¡æ¯ï¼ˆåŒ…å«é‡è¯•ä¿¡æ¯ï¼‰
	bt.logger.Info("translation completed",
		zap.Int("completed", successCount),
		zap.Int("failed", failedCount),
		zap.Int("total", len(nodes)),
		zap.Float64("progress", progressPercent),
		zap.Int("maxRetries", maxRetries),
		zap.String("retryStatus", func() string {
			if failedCount > 0 {
				return "some nodes failed after retries"
			}
			return "all retries successful"
		}()))

	// æ˜¾ç¤ºç»Ÿè®¡è¡¨æ ¼ï¼ˆå¦‚æœé…ç½®äº†ç»Ÿè®¡ç®¡ç†å™¨ï¼‰
	if bt.statsManager != nil && bt.config.ShowStatsTable {
		bt.statsManager.PrintStatsTable()
	}

	return nil
}

// processGroups å¹¶è¡Œå¤„ç†èŠ‚ç‚¹ç»„
func (bt *BatchTranslator) processGroups(ctx context.Context, groups []*document.NodeGroup) {
	concurrency := bt.config.Concurrency
	if concurrency <= 0 {
		concurrency = 4
	}

	// åˆ›å»ºå·¥ä½œé˜Ÿåˆ—å’Œè¿›åº¦è¿½è¸ª
	groupChan := make(chan *document.NodeGroup, len(groups))
	errChan := make(chan error, len(groups))
	progressChan := make(chan int, len(groups))

	// è®¡ç®—æ€»èŠ‚ç‚¹æ•°
	totalNodes := 0
	for _, group := range groups {
		totalNodes += len(group.Nodes)
	}

	// å°†æ‰€æœ‰ç»„æ”¾å…¥é˜Ÿåˆ—
	for _, group := range groups {
		groupChan <- group
	}
	close(groupChan)

	// å¯åŠ¨è¿›åº¦ç›‘æ§ goroutine
	processedGroups := 0
	processedNodes := 0
	go func() {
		for completedInGroup := range progressChan {
			processedGroups++
			processedNodes += completedInGroup
			progress := float64(processedGroups) / float64(len(groups)) * 100

			// è°ƒç”¨è¿›åº¦å›è°ƒ
			bt.callProgressCallback(processedNodes, totalNodes,
				fmt.Sprintf("å¤„ç†ä¸­ï¼š%d/%d ç»„ï¼Œ%d/%d èŠ‚ç‚¹", processedGroups, len(groups), processedNodes, totalNodes))

			bt.logger.Debug("translation progress",
				zap.Int("completed_groups", processedGroups),
				zap.Int("total_groups", len(groups)),
				zap.Int("completed_nodes", processedNodes),
				zap.Int("total_nodes", totalNodes),
				zap.Int("nodes_in_current_group", completedInGroup),
				zap.Float64("progress", progress))
		}
	}()

	// å¯åŠ¨å·¥ä½œ goroutines
	var wg sync.WaitGroup
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for group := range groupChan {
				bt.logger.Debug("worker processing group",
					zap.Int("workerID", workerID),
					zap.Int("groupSize", len(group.Nodes)))

				if err := bt.translateGroup(ctx, group); err != nil {
					// æå–è¯¦ç»†é”™è¯¯ä¿¡æ¯
					var detailedError string
					var errorType string
					var isRetryable bool

					if transErr, ok := err.(*translation.TranslationError); ok {
						detailedError = transErr.Error()
						errorType = transErr.Code
						isRetryable = transErr.IsRetryable()
						if transErr.Cause != nil {
							detailedError += " (cause: " + transErr.Cause.Error() + ")"
						}
					} else {
						detailedError = err.Error()
						errorType = "UNKNOWN_ERROR"
					}

					bt.logger.Error("group translation failed",
						zap.Int("workerID", workerID),
						zap.Int("groupSize", len(group.Nodes)),
						zap.String("errorType", errorType),
						zap.String("detailedError", detailedError),
						zap.Bool("retryable", isRetryable))
					errChan <- err
				}

				// å‘é€è¿›åº¦æ›´æ–°
				progressChan <- len(group.Nodes)
			}
		}(i)
	}

	// ç­‰å¾…æ‰€æœ‰å·¥ä½œå®Œæˆ
	wg.Wait()
	close(errChan)
	close(progressChan)
}

// translateGroup ç¿»è¯‘ä¸€ä¸ªèŠ‚ç‚¹ç»„
func (bt *BatchTranslator) translateGroup(ctx context.Context, group *document.NodeGroup) error {
	if bt.translationService == nil {
		// æ¨¡æ‹Ÿç¿»è¯‘
		for _, node := range group.Nodes {
			node.TranslatedText = "Translated: " + node.OriginalText
			node.Status = document.NodeStatusSuccess
		}
		return nil
	}

	// ä¿æŠ¤ä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹
	protectedTexts := make(map[int]string) // nodeID -> protected text
	preserveManager := translation.NewPreserveManager(translation.DefaultPreserveConfig)

	// æ„å»ºæ‰¹é‡ç¿»è¯‘æ–‡æœ¬
	var builder strings.Builder
	needsTranslation := false

	for _, node := range group.Nodes {
		// æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡èŠ‚ç‚¹ï¼ˆå·²ç»ç¿»è¯‘è¿‡çš„ï¼‰
		isContext := false
		if node.Metadata != nil {
			if ctx, ok := node.Metadata["is_context"].(bool); ok && ctx {
				isContext = true
			}
		}

		// å¦‚æœæ˜¯ä¸Šä¸‹æ–‡èŠ‚ç‚¹ä¸”å·²æˆåŠŸï¼Œä½¿ç”¨å·²ç¿»è¯‘çš„æ–‡æœ¬
		if isContext && node.Status == document.NodeStatusSuccess {
			// æ·»åŠ èŠ‚ç‚¹æ ‡è®°
			if builder.Len() > 0 {
				builder.WriteString("\n\n")
			}
			builder.WriteString(fmt.Sprintf("@@NODE_START_%d@@\n", node.ID))
			builder.WriteString(node.TranslatedText)
			builder.WriteString(fmt.Sprintf("\n@@NODE_END_%d@@", node.ID))
		} else {
			// ä¿æŠ¤å†…å®¹
			protectedText := bt.protectContent(node.OriginalText, preserveManager)
			protectedTexts[node.ID] = protectedText

			// æ£€æŸ¥æ˜¯å¦æ˜¯çº¯ä¿æŠ¤å†…å®¹
			if bt.isOnlyProtectedContent(protectedText, preserveManager) {
				// çº¯ä¿æŠ¤å†…å®¹èŠ‚ç‚¹ï¼Œç›´æ¥æ ‡è®°ä¸ºæˆåŠŸå¹¶ä½¿ç”¨åŸæ–‡
				node.Status = document.NodeStatusSuccess
				node.TranslatedText = node.OriginalText
				
				bt.logger.Debug("skipping protected-only node - not included in translation request",
					zap.Int("nodeID", node.ID),
					zap.String("content", truncateText(node.OriginalText, 100)))
				
				// ä¸æ·»åŠ åˆ° combinedText ä¸­ï¼Œå®Œå…¨è·³è¿‡
			} else {
				// éœ€è¦ç¿»è¯‘çš„èŠ‚ç‚¹
				needsTranslation = true

				// åœ¨è¯¦ç»†æ¨¡å¼ä¸‹è®°å½•ä¿æŠ¤ä¿¡æ¯
				if bt.config.Verbose && protectedText != node.OriginalText {
					bt.logger.Debug("content protection applied",
						zap.Int("nodeID", node.ID),
						zap.String("originalLength", fmt.Sprintf("%d chars", len(node.OriginalText))),
						zap.String("protectedLength", fmt.Sprintf("%d chars", len(protectedText))),
						zap.String("originalSample", truncateText(node.OriginalText, 100)),
						zap.String("protectedSample", truncateText(protectedText, 100)))
				}

				// åªæœ‰éœ€è¦ç¿»è¯‘çš„èŠ‚ç‚¹æ‰æ·»åŠ åˆ° combinedText
				if builder.Len() > 0 {
					builder.WriteString("\n\n")
				}
				builder.WriteString(fmt.Sprintf("@@NODE_START_%d@@\n", node.ID))
				builder.WriteString(protectedText)
				builder.WriteString(fmt.Sprintf("\n@@NODE_END_%d@@", node.ID))
			}
		}
	}

	// å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯ä¸Šä¸‹æ–‡èŠ‚ç‚¹æˆ–ä¿æŠ¤å†…å®¹ï¼Œè·³è¿‡ç¿»è¯‘
	if !needsTranslation {
		bt.logger.Debug("skipping group - all nodes are context or protected-only",
			zap.Int("groupSize", len(group.Nodes)))
		return nil
	}

	combinedText := builder.String()

	// æ£€æŸ¥æœ€ç»ˆçš„ç»„åˆæ–‡æœ¬æ˜¯å¦ä¸ºç©ºï¼ˆæ‰€æœ‰èŠ‚ç‚¹éƒ½è¢«è·³è¿‡äº†ï¼‰
	if strings.TrimSpace(combinedText) == "" {
		bt.logger.Debug("skipping group - final combinedText is empty after selective filtering",
			zap.Int("groupSize", len(group.Nodes)),
			zap.Bool("needsTranslation", needsTranslation))
		return nil
	}

	// ç»Ÿè®¡éœ€è¦ç¿»è¯‘çš„èŠ‚ç‚¹æ•°
	nodesToTranslate := 0
	contextNodes := 0
	var nodeIDsToTranslate []int
	for _, node := range group.Nodes {
		if node.Metadata != nil {
			if ctx, ok := node.Metadata["is_context"].(bool); ok && ctx {
				contextNodes++
				continue
			}
		}
		nodesToTranslate++
		nodeIDsToTranslate = append(nodeIDsToTranslate, node.ID)
	}

	// è®°å½•å‡†å¤‡ç¿»è¯‘çš„èŠ‚ç‚¹ä¿¡æ¯
	bt.logger.Info("preparing batch translation request",
		zap.Ints("inputNodeIDs", nodeIDsToTranslate),
		zap.Int("totalNodes", len(group.Nodes)),
		zap.Int("nodesToTranslate", nodesToTranslate),
		zap.Int("contextNodes", contextNodes),
		zap.Int("textLength", len(combinedText)))

	// åœ¨å‘é€å‰è®°å½•è¯¦ç»†çš„è¯·æ±‚å†…å®¹
	bt.logger.Debug("sending batch translation request",
		zap.Int("requestLength", len(combinedText)),
		zap.Int("nodeCount", len(group.Nodes)),
		zap.String("requestPreview", truncateText(combinedText, 500)))

	// å¦‚æœæ˜¯ verbose æ¨¡å¼ï¼Œè®°å½•å®Œæ•´çš„èŠ‚ç‚¹æ ‡è®°
	if bt.config.Verbose {
		// æå–æ‰€æœ‰èŠ‚ç‚¹æ ‡è®°
		nodeMarkers := []string{}
		lines := strings.Split(combinedText, "\n")
		for _, line := range lines {
			if strings.Contains(line, "@@NODE_START_") || strings.Contains(line, "@@NODE_END_") {
				nodeMarkers = append(nodeMarkers, line)
			}
		}
		bt.logger.Debug("node markers in request",
			zap.Strings("markers", nodeMarkers))
	}

	// æ‰§è¡Œç¿»è¯‘ - ä½¿ç”¨ç®€åŒ–çš„æ¥å£ï¼Œæ— åˆ†å—
	startTime := time.Now()
	translatedText, err := bt.translationService.TranslateText(ctx, combinedText)
	latency := time.Since(startTime)
	if err != nil {
		bt.logger.Error("translation service error",
			zap.Error(err),
			zap.Int("nodeCount", len(group.Nodes)))
		// æ ‡è®°æ‰€æœ‰èŠ‚ç‚¹å¤±è´¥
		for _, node := range group.Nodes {
			node.Status = document.NodeStatusFailed
			node.Error = err
		}
		return err
	}

	// è®°å½•å“åº”è¯¦æƒ…
	bt.logger.Debug("received translation response",
		zap.Int("responseLength", len(translatedText)),
		zap.String("responsePreview", truncateText(translatedText, 500)))
	// æ£€æŸ¥å“åº”æ ¼å¼
	isJSON := strings.HasPrefix(strings.TrimSpace(translatedText), "{") || strings.HasPrefix(strings.TrimSpace(translatedText), "[")
	isEmpty := len(strings.TrimSpace(translatedText)) == 0

	// æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«èŠ‚ç‚¹æ ‡è®°
	hasStartMarkers := strings.Contains(translatedText, "@@NODE_START_")
	hasEndMarkers := strings.Contains(translatedText, "@@NODE_END_")

	// æ ¹æ®èŠ‚ç‚¹æ ‡è®°å­˜åœ¨æƒ…å†µé€‰æ‹©æ—¥å¿—çº§åˆ«
	if !hasStartMarkers || !hasEndMarkers {
		bt.logger.Warn("response format check - missing node markers",
			zap.Bool("hasStartMarkers", hasStartMarkers),
			zap.Bool("hasEndMarkers", hasEndMarkers),
			zap.Bool("isJSON", isJSON),
			zap.Bool("isEmpty", isEmpty),
			zap.Int("responseLength", len(translatedText)))
	} else {
		bt.logger.Debug("response format check - markers found",
			zap.Bool("hasStartMarkers", hasStartMarkers),
			zap.Bool("hasEndMarkers", hasEndMarkers))
	}

	// å¦‚æœå“åº”çœ‹èµ·æ¥åƒ JSONï¼Œå°è¯•æå–å…¶ä¸­çš„æ–‡æœ¬
	if isJSON && !hasStartMarkers {
		bt.logger.Warn("response appears to be JSON without node markers",
			zap.String("jsonPreview", truncateText(translatedText, 200)))
	}

	// å¦‚æœæ²¡æœ‰æ‰¾åˆ°èŠ‚ç‚¹æ ‡è®°ï¼Œè¿è¡Œè¯Šæ–­å¹¶å°è¯•é‡è¯•
	if !hasStartMarkers || !hasEndMarkers {
		diagnostic := DiagnoseBatchTranslationIssue(combinedText, translatedText)
		bt.logger.Warn("batch translation diagnostic",
			zap.String("diagnostic", diagnostic.Format()))

		// æ£€æŸ¥æ˜¯å¦å¯ä»¥é‡è¯•ï¼ˆé¿å…æ— é™é‡è¯•ï¼‰
		maxNodeMarkerRetries := 2
		currentRetries := 0
		if context, ok := ctx.Value("node_marker_retries").(int); ok {
			currentRetries = context
		}

		if currentRetries < maxNodeMarkerRetries {
			bt.logger.Warn("node markers missing, attempting retry with enhanced prompt",
				zap.Int("currentRetry", currentRetries),
				zap.Int("maxRetries", maxNodeMarkerRetries))

			// åˆ›å»ºæ–°çš„ä¸Šä¸‹æ–‡ï¼Œå¢åŠ é‡è¯•è®¡æ•°
			newCtx := context.WithValue(ctx, "node_marker_retries", currentRetries+1)

			// ä½¿ç”¨å¢å¼ºçš„æç¤ºè¯é‡è¯•
			enhancedRequest := bt.buildEnhancedNodeMarkerRequest(combinedText)
			retryResponseText, retryErr := bt.translationService.TranslateText(newCtx, enhancedRequest)

			if retryErr == nil && retryResponseText != "" {
				bt.logger.Info("retry with enhanced prompt completed",
					zap.Int("retryAttempt", currentRetries+1),
					zap.Int("responseLength", len(retryResponseText)))

				// æ£€æŸ¥é‡è¯•çš„å“åº”æ˜¯å¦åŒ…å«æ ‡è®°
				retryHasMarkers := strings.Contains(retryResponseText, "@@NODE_START_") &&
					strings.Contains(retryResponseText, "@@NODE_END_")

				if retryHasMarkers {
					bt.logger.Info("enhanced prompt retry successful - node markers found")
					// ä½¿ç”¨é‡è¯•çš„å“åº”æ›¿æ¢åŸå§‹å“åº”
					translatedText = retryResponseText
					hasStartMarkers = true
					hasEndMarkers = true
				} else {
					bt.logger.Warn("enhanced prompt retry failed - still no node markers")
				}
			} else {
				bt.logger.Error("enhanced prompt retry failed",
					zap.Error(retryErr))
			}
		} else {
			bt.logger.Error("node marker retry limit exceeded",
				zap.Int("maxRetries", maxNodeMarkerRetries),
				zap.String("issue", "LLM consistently ignores node markers"))
		}
	}

	// å¦‚æœæ˜¯ verbose æ¨¡å¼ï¼Œè®°å½•å“åº”ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹æ ‡è®°
	if bt.config.Verbose {
		responseMarkers := []string{}
		lines := strings.Split(translatedText, "\n")
		for i, line := range lines {
			if strings.Contains(line, "@@NODE_START_") || strings.Contains(line, "@@NODE_END_") {
				responseMarkers = append(responseMarkers, fmt.Sprintf("Line %d: %s", i+1, line))
			}
		}
		bt.logger.Debug("node markers in response",
			zap.Strings("markers", responseMarkers))

		// è®°å½•å‰å‡ è¡Œå’Œåå‡ è¡Œ
		if len(lines) > 0 {
			numLines := len(lines)
			firstCount := 10
			if numLines < firstCount {
				firstCount = numLines
			}
			firstLines := lines[:firstCount]

			lastStart := numLines - 10
			if lastStart < 0 {
				lastStart = 0
			}
			lastLines := lines[lastStart:]
			bt.logger.Debug("response structure",
				zap.Strings("firstLines", firstLines),
				zap.Strings("lastLines", lastLines))
		}
	}

	// è§£æç¿»è¯‘ç»“æœ - ä½¿ç”¨æ›´å¼ºå¥çš„æ­£åˆ™è¡¨è¾¾å¼å¤„ç†ä¸åŒæ¢è¡Œç¬¦å’Œç©ºæ ¼
	pattern := regexp2.MustCompile(`(?s)@@NODE_START_(\d+)@@\s*\r?\n(.*?)\r?\n\s*@@NODE_END_\1@@`, 0)

	// åˆ›å»ºç»“æœæ˜ å°„
	translationMap := make(map[int]string)

	// å…ˆå°è¯•è°ƒè¯•æ­£åˆ™è¡¨è¾¾å¼
	if bt.config.Verbose {
		// å°è¯•ç®€å•çš„æ­£åˆ™åŒ¹é…æ¥éªŒè¯æ ¼å¼
		simplePattern := regexp2.MustCompile(`@@NODE_START_\d+@@`, 0)
		simpleMatch, _ := simplePattern.FindStringMatch(translatedText)
		simpleMatchCount := 0
		for simpleMatch != nil {
			simpleMatchCount++
			simpleMatch, _ = simplePattern.FindNextMatch(simpleMatch)
		}
		bt.logger.Debug("simple pattern match test",
			zap.Int("simpleMatchCount", simpleMatchCount))

		// é¢å¤–è°ƒè¯•ï¼šæ£€æŸ¥å“åº”ä¸­çš„æ¢è¡Œç¬¦ç±»å‹
		bt.logger.Debug("response newline analysis",
			zap.Bool("containsCRLF", strings.Contains(translatedText, "\r\n")),
			zap.Bool("containsLF", strings.Contains(translatedText, "\n")),
			zap.Bool("containsCR", strings.Contains(translatedText, "\r")))
	}

	// ä½¿ç”¨ regexp2 æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
	match, err := pattern.FindStringMatch(translatedText)
	if err != nil {
		bt.logger.Error("regex error", zap.Error(err))
	}

	matchCount := 0
	foundNodeIDs := []int{}

	for match != nil {
		groups := match.Groups()
		if bt.config.Verbose && matchCount < 3 {
			// è®°å½•å‰å‡ ä¸ªåŒ¹é…çš„è¯¦ç»†ä¿¡æ¯
			bt.logger.Debug("regex match details",
				zap.Int("matchNumber", matchCount+1),
				zap.Int("groupCount", len(groups)),
				zap.String("fullMatch", groups[0].String()))
		}

		if len(groups) >= 3 {
			nodeIDStr := groups[1].String()
			nodeID, err := strconv.Atoi(nodeIDStr)
			if err != nil {
				bt.logger.Warn("invalid node ID",
					zap.String("nodeID", nodeIDStr),
					zap.Error(err))
				match, _ = pattern.FindNextMatch(match)
				continue
			}
			content := groups[2].String()
			translationMap[nodeID] = strings.TrimSpace(content)
			matchCount++
			foundNodeIDs = append(foundNodeIDs, nodeID)

			if bt.config.Verbose && matchCount <= 3 {
				bt.logger.Debug("parsed node translation",
					zap.Int("nodeID", nodeID),
					zap.String("contentPreview", truncateText(content, 100)))
			}
		}
		match, _ = pattern.FindNextMatch(match)
	}

	// é‡ç”¨ä¹‹å‰è®¡ç®—çš„nodeIDsToTranslateä½œä¸ºinputNodeIDs
	inputNodeIDs := nodeIDsToTranslate

	// è®°å½•æœŸæœ›ä½†æœªæ‰¾åˆ°çš„èŠ‚ç‚¹
	var missingNodeIDs []int
	for _, nodeID := range inputNodeIDs {
		if _, found := translationMap[nodeID]; !found {
			missingNodeIDs = append(missingNodeIDs, nodeID)
		}
	}

	// è®¡ç®—è§£ææˆåŠŸç‡
	successRate := float64(len(foundNodeIDs)) / float64(len(inputNodeIDs)) * 100

	// æ ¹æ®ç»“æœé€‰æ‹©åˆé€‚çš„æ—¥å¿—çº§åˆ«
	if len(missingNodeIDs) > 0 {
		bt.logger.Warn("batch translation parsing results",
			zap.Ints("inputNodeIDs", inputNodeIDs),
			zap.Ints("foundNodeIDs", foundNodeIDs),
			zap.Ints("missingNodeIDs", missingNodeIDs),
			zap.Int("inputCount", len(inputNodeIDs)),
			zap.Int("foundCount", len(foundNodeIDs)),
			zap.Int("missingCount", len(missingNodeIDs)),
			zap.Float64("successRate", successRate),
			zap.Int("responseLength", len(translatedText)))
	} else {
		bt.logger.Info("batch translation parsing successful",
			zap.Ints("inputNodeIDs", inputNodeIDs),
			zap.Ints("foundNodeIDs", foundNodeIDs),
			zap.Int("nodeCount", len(foundNodeIDs)),
			zap.Float64("successRate", successRate))
	}

	if bt.config.Verbose {
		// æ˜¾ç¤ºç¿»è¯‘ç‰‡æ®µï¼ˆæ¸…ç†æ¨ç†æ ‡è®°åæ˜¾ç¤ºï¼‰
		if matchCount > 0 {
			cleanedText := translation.RemoveReasoningMarkers(translatedText)
			bt.logger.Debug("translation snippets",
				zap.Int("totalMatches", matchCount),
				zap.String("firstSnippet", truncateText(cleanedText, 300)))
		}

		// è¯¦ç»†çš„è§£æç»Ÿè®¡
		bt.logger.Debug("detailed parsing stats",
			zap.Int("totalNodes", len(group.Nodes)),
			zap.Int("nodesToTranslate", nodesToTranslate),
			zap.Int("contextNodes", contextNodes),
			zap.Int("translatedTextLength", len(translatedText)))
	}

	// åº”ç”¨ç¿»è¯‘ç»“æœ
	for _, node := range group.Nodes {
		// æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡èŠ‚ç‚¹
		isContext := false
		if node.Metadata != nil {
			if ctx, ok := node.Metadata["is_context"].(bool); ok && ctx {
				isContext = true
			}
		}

		// ä¸Šä¸‹æ–‡èŠ‚ç‚¹ä¿æŒåŸçŠ¶
		if isContext && node.Status == document.NodeStatusSuccess {
			continue
		}

		// å¤„ç†éœ€è¦ç¿»è¯‘çš„èŠ‚ç‚¹
		if translatedContent, ok := translationMap[node.ID]; ok {

			// è¿˜åŸä¿æŠ¤çš„å†…å®¹
			restoredText := preserveManager.Restore(translatedContent)

			// æ£€æŸ¥ç¿»è¯‘è´¨é‡ - å»æ‰ä¿æŠ¤ç¬¦å·åæ¯”è¾ƒåŸæ–‡å’Œè¯‘æ–‡
			cleanOriginal := preserveManager.RemoveProtectionMarkers(node.OriginalText)
			cleanTranslated := preserveManager.RemoveProtectionMarkers(restoredText)

			// å¦‚æœå»æ‰ä¿æŠ¤ç¬¦å·åå†…å®¹å¤ªçŸ­ï¼Œè·³è¿‡ç›¸ä¼¼åº¦æ£€æŸ¥
			cleanOriginalLen := len(strings.TrimSpace(cleanOriginal))
			cleanTranslatedLen := len(strings.TrimSpace(cleanTranslated))
			minLengthForCheck := 20 // å°‘äº20å­—ç¬¦çš„å†…å®¹ä¸æ£€æŸ¥ç›¸ä¼¼åº¦

			shouldCheckSimilarity := cleanOriginalLen >= minLengthForCheck && cleanTranslatedLen >= minLengthForCheck

			var similarity float64
			if shouldCheckSimilarity {
				similarity = bt.calculateSimilarity(cleanOriginal, cleanTranslated)
			} else {
				similarity = 0.0 // çŸ­å†…å®¹é»˜è®¤é€šè¿‡æ£€æŸ¥
			}

			// ç›¸ä¼¼åº¦é˜ˆå€¼ - å¯¹äºå­¦æœ¯è®ºæ–‡ç­‰åŒ…å«å¤§é‡æœ¯è¯­çš„æ–‡æœ¬ï¼Œä½¿ç”¨è¾ƒé«˜çš„é˜ˆå€¼
			similarityThreshold := 0.95 // åªæœ‰å‡ ä¹å®Œå…¨ä¸€æ ·æ—¶æ‰è®¤ä¸ºå¤±è´¥

			if shouldCheckSimilarity && similarity >= similarityThreshold {
				// ç¿»è¯‘ç»“æœä¸åŸæ–‡å¤ªç›¸ä¼¼ï¼Œè§†ä¸ºå¤±è´¥
				node.Status = document.NodeStatusFailed
				node.Error = fmt.Errorf("translation too similar to original (similarity: %.2f)", similarity)
				node.RetryCount++

				if bt.config.Verbose {
					bt.logger.Warn("translation quality check failed",
						zap.Int("nodeID", node.ID),
						zap.Float64("similarity", similarity),
						zap.Float64("threshold", similarityThreshold),
						zap.Int("cleanOriginalLen", cleanOriginalLen),
						zap.Int("cleanTranslatedLen", cleanTranslatedLen),
						zap.String("cleanOriginal", truncateText(cleanOriginal, 100)),
						zap.String("cleanTranslated", truncateText(cleanTranslated, 100)),
						zap.String("restoredText", truncateText(restoredText, 100)))
				} else {
					bt.logger.Warn("translation quality check failed",
						zap.Int("nodeID", node.ID),
						zap.Float64("similarity", similarity),
						zap.Float64("threshold", similarityThreshold),
						zap.Int("cleanOriginalLen", cleanOriginalLen),
						zap.Int("cleanTranslatedLen", cleanTranslatedLen))
				}
			} else {
				// ç¿»è¯‘æˆåŠŸ
				// ç§»é™¤æ¨ç†æ¨¡å‹çš„æ€è€ƒæ ‡è®°
				finalText := translation.RemoveReasoningMarkers(restoredText)
				node.TranslatedText = finalText
				node.Status = document.NodeStatusSuccess
				node.Error = nil
				// å¢åŠ é‡è¯•è®¡æ•°
				node.RetryCount++

				// åœ¨ verbose æ¨¡å¼ä¸‹æ˜¾ç¤ºæˆåŠŸç¿»è¯‘çš„ç‰‡æ®µ
				if bt.config.Verbose {
					bt.logger.Debug("translation success",
						zap.Int("nodeID", node.ID),
						zap.String("original", truncateText(node.OriginalText, 100)),
						zap.String("translated", truncateText(finalText, 100)))
				}
			}
		} else {
			node.Status = document.NodeStatusFailed
			node.Error = fmt.Errorf("translation not found in batch result for node %d", node.ID)
			node.RetryCount++

			// å°è¯•æŸ¥æ‰¾å¯èƒ½è¢«ä¿®æ”¹çš„èŠ‚ç‚¹æ ‡è®°
			alternativePatterns := []string{
				fmt.Sprintf("NODE_START_%d", node.ID),
				fmt.Sprintf("@@NODE_%d@@", node.ID),
				fmt.Sprintf("NODE %d:", node.ID),
				fmt.Sprintf("<%d>", node.ID),
			}

			foundAlternative := false
			for _, pattern := range alternativePatterns {
				if strings.Contains(translatedText, pattern) {
					foundAlternative = true
					bt.logger.Warn("found alternative node marker",
						zap.Int("nodeID", node.ID),
						zap.String("pattern", pattern))
					break
				}
			}

			// èŠ‚ç‚¹ç¿»è¯‘å¤±è´¥æ˜¯é‡è¦ä¿¡æ¯ï¼Œä½¿ç”¨WARNçº§åˆ«
			bt.logger.Warn("node translation not found",
				zap.Int("nodeID", node.ID),
				zap.String("originalText", truncateText(node.OriginalText, 100)),
				zap.Bool("isContext", isContext),
				zap.Bool("foundAlternative", foundAlternative))
		}
	}

	// è®°å½•Provideræ€§èƒ½ç»Ÿè®¡
	if bt.statsManager != nil {
		bt.recordGroupStats(ctx, group, nodeIDsToTranslate, err, latency)
	}

	return nil
}

// recordGroupStats è®°å½•ç»„ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯
func (bt *BatchTranslator) recordGroupStats(ctx context.Context, group *document.NodeGroup, nodeIDsToTranslate []int, translationErr error, latency time.Duration) {
	if bt.statsManager == nil {
		return
	}

	// é»˜è®¤ä½¿ç”¨é€šç”¨Provideråç§°ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä»é…ç½®æˆ–serviceä¸­è·å–ï¼‰
	providerName := "unknown"
	modelName := "unknown"

	// è®¡ç®—èŠ‚ç‚¹æ ‡è®°ç»Ÿè®¡
	expectedMarkers := len(nodeIDsToTranslate)
	actualMarkers := 0
	lostMarkers := 0

	// è®¡ç®—æˆåŠŸå’Œå¤±è´¥èŠ‚ç‚¹
	successfulNodes := 0
	failedNodes := 0
	hasSimilarityIssues := false
	hasFormatIssues := false
	hasReasoningTags := false

	for _, node := range group.Nodes {
		if node.Status == document.NodeStatusSuccess {
			successfulNodes++
			// æ£€æŸ¥èŠ‚ç‚¹æ ‡è®°
			if strings.Contains(node.TranslatedText, fmt.Sprintf("@@NODE_START_%d@@", node.ID)) {
				actualMarkers++
			}
			// æ£€æŸ¥æ˜¯å¦æœ‰æ¨ç†æ ‡è®°
			if translation.HasReasoningTags(node.TranslatedText) {
				hasReasoningTags = true
			}
		} else {
			failedNodes++
			// æ£€æŸ¥å¤±è´¥åŸå› 
			if node.Error != nil {
				errorStr := strings.ToLower(node.Error.Error())
				if strings.Contains(errorStr, "similarity") {
					hasSimilarityIssues = true
				}
			}
		}
	}

	lostMarkers = expectedMarkers - actualMarkers

	// åˆ›å»ºç»Ÿè®¡ç»“æœ
	result := stats.RequestResult{
		Success:           translationErr == nil && failedNodes == 0,
		Latency:           latency,
		NodeMarkersFound:  actualMarkers,
		NodeMarkersLost:   lostMarkers,
		HasFormatIssues:   hasFormatIssues,
		HasReasoningTags:  hasReasoningTags,
		SimilarityTooHigh: hasSimilarityIssues,
		IsRetry:           false, // TODO: å¯ä»¥ä»ä¸Šä¸‹æ–‡ä¸­è·å–
	}

	if translationErr != nil {
		result.ErrorType = bt.classifyTranslationError(translationErr)
	}

	// è®°å½•ç»Ÿè®¡
	bt.statsManager.RecordRequest(providerName, modelName, result)

	bt.logger.Debug("recorded translation statistics",
		zap.String("provider", providerName),
		zap.String("model", modelName),
		zap.Bool("success", result.Success),
		zap.Duration("latency", latency),
		zap.Int("expectedMarkers", expectedMarkers),
		zap.Int("actualMarkers", actualMarkers),
		zap.Int("lostMarkers", lostMarkers))
}

// classifyTranslationError åˆ†ç±»ç¿»è¯‘é”™è¯¯
func (bt *BatchTranslator) classifyTranslationError(err error) string {
	if err == nil {
		return ""
	}

	errorStr := strings.ToLower(err.Error())
	switch {
	case strings.Contains(errorStr, "timeout"):
		return "timeout"
	case strings.Contains(errorStr, "rate limit"):
		return "rate_limit"
	case strings.Contains(errorStr, "context"):
		return "context_error"
	case strings.Contains(errorStr, "network"):
		return "network_error"
	case strings.Contains(errorStr, "auth"):
		return "auth_error"
	case strings.Contains(errorStr, "quota"):
		return "quota_exceeded"
	default:
		return "unknown_error"
	}
}

// protectContent ä¿æŠ¤ä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹
func (bt *BatchTranslator) protectContent(text string, pm *translation.PreserveManager) string {
	// LaTeX å…¬å¼ - ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼
	text = pm.ProtectPattern(text, `\$[^$\n]+\$`)      // è¡Œå†…å…¬å¼ (ä¸åŒ…å«æ¢è¡Œ)
	text = pm.ProtectPattern(text, `\$\$[\s\S]*?\$\$`) // è¡Œé—´å…¬å¼ (éè´ªå©ªåŒ¹é…)
	text = pm.ProtectPattern(text, `\\\([\s\S]*?\\\)`) // \(...\) (éè´ªå©ªåŒ¹é…)
	text = pm.ProtectPattern(text, `\\\[[\s\S]*?\\\]`) // \[...\] (éè´ªå©ªåŒ¹é…)

	// ä»£ç å—
	text = pm.ProtectPattern(text, "`[^`]+`") // è¡Œå†…ä»£ç 
	text = protectCodeBlocks(text, pm)        // å¤šè¡Œä»£ç å—

	// HTML æ ‡ç­¾
	text = pm.ProtectPattern(text, `<[^>]+>`)     // HTML æ ‡ç­¾
	text = pm.ProtectPattern(text, `&[a-zA-Z]+;`) // HTML å®ä½“
	text = pm.ProtectPattern(text, `&#\d+;`)      // æ•°å­—å®ä½“

	// URL
	text = pm.ProtectPattern(text, `(?i)(https?|ftp|file)://[^\s\)]+`)
	text = pm.ProtectPattern(text, `(?i)www\.[^\s\)]+`)

	// æ–‡ä»¶è·¯å¾„
	text = pm.ProtectPattern(text, `(?:^|[\s(])/(?:[^/\s]+/)*[^/\s]+(?:\.[a-zA-Z0-9]+)?`)
	text = pm.ProtectPattern(text, `[A-Za-z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]+`)
	text = pm.ProtectPattern(text, `\.{1,2}/(?:[^/\s]+/)*[^/\s]+(?:\.[a-zA-Z0-9]+)?`)

	// Markdown å›¾ç‰‡å’Œé“¾æ¥
	text = pm.ProtectPattern(text, `!\[[^\]]*\]\([^)]+\)`)      // ![alt text](image url)
	text = pm.ProtectPattern(text, `\[[^\]]+\]\([^)]+\)`)       // [link text](url)
	text = pm.ProtectPattern(text, `\[[^\]]+\]\[[^\]]*\]`)      // [link text][ref]
	text = pm.ProtectPattern(text, `(?m)^\s*\[[^\]]+\]:\s*.+$`) // [ref]: url (å¼•ç”¨å®šä¹‰ï¼Œå¤šè¡Œæ¨¡å¼)

	// å¼•ç”¨æ ‡è®°
	text = pm.ProtectPattern(text, `\[\d+\]`)                                 // [1], [2]
	text = pm.ProtectPattern(text, `\[[A-Za-z]+(?:\s+et\s+al\.)?,\s*\d{4}\]`) // [Author, Year]
	text = pm.ProtectPattern(text, `\\cite\{[^}]+\}`)                         // \cite{}
	text = pm.ProtectPattern(text, `\\ref\{[^}]+\}`)                          // \ref{}
	text = pm.ProtectPattern(text, `\\label\{[^}]+\}`)                        // \label{}

	// å…¶ä»–
	text = pm.ProtectPattern(text, `\{\{[^}]+\}\}`)                                  // {{variable}}
	text = pm.ProtectPattern(text, `<%[^%]+%>`)                                      // <% %>
	text = pm.ProtectPattern(text, `<!--[\s\S]*?-->`)                                // <!-- -->
	text = pm.ProtectPattern(text, `[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}`) // é‚®ç®±

	return text
}

// protectCodeBlocks ä¿æŠ¤å¤šè¡Œä»£ç å—
func protectCodeBlocks(text string, pm *translation.PreserveManager) string {
	lines := strings.Split(text, "\n")
	inCodeBlock := false
	codeBlockContent := []string{}
	result := []string{}

	for _, line := range lines {
		if strings.HasPrefix(line, "```") {
			if !inCodeBlock {
				inCodeBlock = true
				codeBlockContent = []string{line}
			} else {
				codeBlockContent = append(codeBlockContent, line)
				codeBlock := strings.Join(codeBlockContent, "\n")
				placeholder := pm.Protect(codeBlock)
				result = append(result, placeholder)
				inCodeBlock = false
				codeBlockContent = []string{}
			}
		} else if inCodeBlock {
			codeBlockContent = append(codeBlockContent, line)
		} else {
			result = append(result, line)
		}
	}

	if inCodeBlock {
		result = append(result, codeBlockContent...)
	}

	return strings.Join(result, "\n")
}

// groupNodes å°†èŠ‚ç‚¹åˆ†ç»„ï¼ˆæ”¯æŒæ™ºèƒ½åˆ†å‰²ï¼‰
func (bt *BatchTranslator) groupNodes(nodes []*document.NodeInfo) []*document.NodeGroup {
	// ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½åˆ†å‰²è¶…å¤§èŠ‚ç‚¹
	processedNodes := bt.preprocessNodesWithSplitting(nodes)

	// ç¬¬äºŒæ­¥ï¼šè¿›è¡Œå¸¸è§„åˆ†ç»„
	var groups []*document.NodeGroup
	var currentGroup []*document.NodeInfo
	currentSize := 0

	maxSize := bt.config.ChunkSize
	if maxSize <= 0 {
		maxSize = 1000
	}

	for _, node := range processedNodes {
		nodeSize := len(node.OriginalText)

		// å¦‚æœå½“å‰ç»„åŠ ä¸Šè¿™ä¸ªèŠ‚ç‚¹ä¼šè¶…è¿‡é™åˆ¶ï¼Œå…ˆä¿å­˜å½“å‰ç»„
		if currentSize > 0 && currentSize+nodeSize > maxSize {
			groups = append(groups, &document.NodeGroup{
				Nodes: currentGroup,
				Size:  currentSize,
			})
			currentGroup = nil
			currentSize = 0
		}

		currentGroup = append(currentGroup, node)
		currentSize += nodeSize
	}

	// ä¿å­˜æœ€åä¸€ç»„
	if len(currentGroup) > 0 {
		groups = append(groups, &document.NodeGroup{
			Nodes: currentGroup,
			Size:  currentSize,
		})
	}

	return groups
}

// preprocessNodesWithSplitting é¢„å¤„ç†èŠ‚ç‚¹ï¼Œå¯¹è¶…å¤§èŠ‚ç‚¹è¿›è¡Œæ™ºèƒ½åˆ†å‰²
func (bt *BatchTranslator) preprocessNodesWithSplitting(nodes []*document.NodeInfo) []*document.NodeInfo {
	if !bt.config.SmartSplitter.EnableSmartSplitting {
		// æ™ºèƒ½åˆ†å‰²æœªå¯ç”¨ï¼Œç›´æ¥è¿”å›åŸèŠ‚ç‚¹
		return nodes
	}

	var processedNodes []*document.NodeInfo
	nextNodeID := bt.getMaxNodeID(nodes) + 1

	splitNodeCount := 0
	originalOversizedCount := 0

	for _, node := range nodes {
		if bt.smartSplitter.ShouldSplit(node) {
			originalOversizedCount++
			bt.logger.Debug("processing oversized node for smart splitting",
				zap.Int("nodeID", node.ID),
				zap.Int("nodeSize", len(node.OriginalText)),
				zap.Int("threshold", bt.config.SmartSplitter.MaxNodeSizeThreshold))

			// åˆ†å‰²èŠ‚ç‚¹
			subNodes, err := bt.smartSplitter.SplitNode(node, &nextNodeID)
			if err != nil {
				bt.logger.Warn("failed to split oversized node, using original",
					zap.Int("nodeID", node.ID),
					zap.Error(err))
				processedNodes = append(processedNodes, node)
			} else {
				bt.logger.Info("successfully split oversized node",
					zap.Int("originalNodeID", node.ID),
					zap.Int("originalSize", len(node.OriginalText)),
					zap.Int("subNodesCount", len(subNodes)))
				processedNodes = append(processedNodes, subNodes...)
				splitNodeCount++
			}
		} else {
			// èŠ‚ç‚¹å¤§å°åˆé€‚ï¼Œæ— éœ€åˆ†å‰²
			processedNodes = append(processedNodes, node)
		}
	}

	// è®°å½•æ™ºèƒ½åˆ†å‰²ç»Ÿè®¡ä¿¡æ¯
	if originalOversizedCount > 0 {
		bt.logger.Info("smart node splitting completed",
			zap.Int("originalNodesCount", len(nodes)),
			zap.Int("processedNodesCount", len(processedNodes)),
			zap.Int("oversizedNodesFound", originalOversizedCount),
			zap.Int("nodesSplit", splitNodeCount),
			zap.Bool("splittingEnabled", bt.config.SmartSplitter.EnableSmartSplitting),
			zap.Int("maxSizeThreshold", bt.config.SmartSplitter.MaxNodeSizeThreshold))
	}

	return processedNodes
}

// getMaxNodeID è·å–èŠ‚ç‚¹åˆ—è¡¨ä¸­çš„æœ€å¤§ID
func (bt *BatchTranslator) getMaxNodeID(nodes []*document.NodeInfo) int {
	maxID := 0
	for _, node := range nodes {
		if node.ID > maxID {
			maxID = node.ID
		}
	}
	return maxID
}

// buildEnhancedNodeMarkerRequest æ„å»ºå¢å¼ºçš„èŠ‚ç‚¹æ ‡è®°è¯·æ±‚ï¼Œå¼ºè°ƒæ ‡è®°ä¿ç•™
func (bt *BatchTranslator) buildEnhancedNodeMarkerRequest(originalText string) string {
	// åˆ›å»ºæå…¶å¼ºè°ƒèŠ‚ç‚¹æ ‡è®°ä¿ç•™çš„æç¤ºè¯
	enhancedPrompt := fmt.Sprintf(`ğŸš¨ğŸš¨ğŸš¨ EMERGENCY INSTRUCTION - SYSTEM WILL FAIL WITHOUT COMPLIANCE ğŸš¨ğŸš¨ğŸš¨

You are a translation system component. Your task is to translate text while preserving special markers.

âš ï¸ ABSOLUTE REQUIREMENT - NO EXCEPTIONS:
- You MUST copy every @@NODE_START_X@@ marker to your output EXACTLY as shown
- You MUST copy every @@NODE_END_X@@ marker to your output EXACTLY as shown  
- These markers are computer code - DO NOT translate them
- DO NOT remove them, modify them, or change them in any way

REQUIRED FORMAT - Your output must look EXACTLY like this:
@@NODE_START_1@@
[translated content here]
@@NODE_END_1@@

@@NODE_START_2@@  
[translated content here]
@@NODE_END_2@@

CRITICAL: If ANY marker is missing or changed, the entire system will crash and all work will be lost.

TRANSLATE FROM %s TO %s:

%s

Remember: Copy ALL @@NODE_START_X@@ and @@NODE_END_X@@ markers EXACTLY. Only translate the text between markers.`,
		bt.config.SourceLang,
		bt.config.TargetLang,
		originalText)

	return enhancedPrompt
}

// collectFailedNodes æ”¶é›†å¤±è´¥çš„èŠ‚ç‚¹
func (bt *BatchTranslator) collectFailedNodes(nodes []*document.NodeInfo) []*document.NodeInfo {
	var failed []*document.NodeInfo
	for _, node := range nodes {
		if node.Status != document.NodeStatusSuccess {
			failed = append(failed, node)
		}
	}
	return failed
}

// groupFailedNodesWithContext ä¸ºå¤±è´¥èŠ‚ç‚¹æ·»åŠ ä¸Šä¸‹æ–‡å¹¶é‡æ–°åˆ†ç»„
func (bt *BatchTranslator) groupFailedNodesWithContext(allNodes []*document.NodeInfo, failedNodes []*document.NodeInfo, processedNodes map[int]bool) []*document.NodeGroup {
	// åˆ›å»ºèŠ‚ç‚¹IDåˆ°ç´¢å¼•çš„æ˜ å°„
	nodeIDToIndex := make(map[int]int)
	for i, node := range allNodes {
		nodeIDToIndex[node.ID] = i
	}

	// æ”¶é›†éœ€è¦åŒ…å«çš„èŠ‚ç‚¹ï¼ˆå¤±è´¥èŠ‚ç‚¹åŠå…¶ä¸Šä¸‹æ–‡ï¼‰
	includeSet := make(map[int]bool)
	contextNodeCount := 0

	for _, failed := range failedNodes {
		idx, exists := nodeIDToIndex[failed.ID]
		if !exists {
			continue
		}

		// æ·»åŠ å¤±è´¥èŠ‚ç‚¹æœ¬èº«
		includeSet[failed.ID] = true

		// æ·»åŠ å‰é¢çš„ä¸Šä¸‹æ–‡èŠ‚ç‚¹ï¼ˆæœ€å¤š1ä¸ªï¼‰
		if idx > 0 {
			prevNodeID := allNodes[idx-1].ID
			// åªæ·»åŠ å·²æˆåŠŸç¿»è¯‘çš„èŠ‚ç‚¹ä½œä¸ºä¸Šä¸‹æ–‡
			if !includeSet[prevNodeID] && processedNodes[prevNodeID] {
				includeSet[prevNodeID] = true
				contextNodeCount++
			}
		}

		// æ·»åŠ åé¢çš„ä¸Šä¸‹æ–‡èŠ‚ç‚¹ï¼ˆæœ€å¤š1ä¸ªï¼‰
		if idx < len(allNodes)-1 {
			nextNodeID := allNodes[idx+1].ID
			// åªæ·»åŠ å·²æˆåŠŸç¿»è¯‘çš„èŠ‚ç‚¹ä½œä¸ºä¸Šä¸‹æ–‡
			if !includeSet[nextNodeID] && processedNodes[nextNodeID] {
				includeSet[nextNodeID] = true
				contextNodeCount++
			}
		}
	}

	bt.logger.Debug("context nodes added for retry",
		zap.Int("contextNodes", contextNodeCount),
		zap.Int("totalNodesForRetry", len(includeSet)),
		zap.Int("failedNodesCount", len(failedNodes)),
		zap.Int("processedNodesCount", len(processedNodes)))

	// æ”¶é›†æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„èŠ‚ç‚¹ï¼Œä¿æŒåŸå§‹é¡ºåº
	var nodesToTranslate []*document.NodeInfo
	for _, node := range allNodes {
		if includeSet[node.ID] {
			// å¦‚æœæ˜¯å·²æˆåŠŸçš„ä¸Šä¸‹æ–‡èŠ‚ç‚¹ï¼Œæ·»åŠ æ ‡è®°
			if processedNodes[node.ID] && node.Status == document.NodeStatusSuccess {
				if node.Metadata == nil {
					node.Metadata = make(map[string]interface{})
				}
				node.Metadata["is_context"] = true
			}

			// ç›´æ¥ä½¿ç”¨åŸå§‹èŠ‚ç‚¹å¼•ç”¨ï¼Œè¿™æ ·çŠ¶æ€æ›´æ–°ä¼šåæ˜ åˆ°åŸå§‹æ•°ç»„ä¸­
			nodesToTranslate = append(nodesToTranslate, node)
		}
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰èŠ‚ç‚¹éœ€è¦é‡è¯•
	if len(nodesToTranslate) == 0 {
		bt.logger.Warn("no nodes collected for retry",
			zap.Int("originalFailedNodes", len(failedNodes)),
			zap.Int("includeSetSize", len(includeSet)),
			zap.String("possibleCause", "all failed nodes might have been filtered out or context collection failed"))
		return []*document.NodeGroup{}
	}

	bt.logger.Debug("nodes collected for retry",
		zap.Int("nodesToTranslate", len(nodesToTranslate)),
		zap.Int("failedNodes", len(failedNodes)),
		zap.Int("contextNodes", contextNodeCount))

	// åˆ†ç»„
	return bt.groupNodes(nodesToTranslate)
}

// calculateSimilarity è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ç¼–è¾‘è·ç¦»ï¼‰
func (bt *BatchTranslator) calculateSimilarity(text1, text2 string) float64 {
	if text1 == "" && text2 == "" {
		return 1.0
	}

	if text1 == "" || text2 == "" {
		return 0.0
	}

	// ç®€å•çš„ç¼–è¾‘è·ç¦»å®ç°
	len1 := len([]rune(text1))
	len2 := len([]rune(text2))

	// åˆ›å»ºè·ç¦»çŸ©é˜µ
	matrix := make([][]int, len1+1)
	for i := range matrix {
		matrix[i] = make([]int, len2+1)
	}

	// åˆå§‹åŒ–ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—
	for i := 0; i <= len1; i++ {
		matrix[i][0] = i
	}
	for j := 0; j <= len2; j++ {
		matrix[0][j] = j
	}

	// è®¡ç®—ç¼–è¾‘è·ç¦»
	runes1 := []rune(text1)
	runes2 := []rune(text2)

	for i := 1; i <= len1; i++ {
		for j := 1; j <= len2; j++ {
			cost := 0
			if runes1[i-1] != runes2[j-1] {
				cost = 1
			}

			matrix[i][j] = min(
				matrix[i-1][j]+1,      // åˆ é™¤
				matrix[i][j-1]+1,      // æ’å…¥
				matrix[i-1][j-1]+cost, // æ›¿æ¢
			)
		}
	}

	// è®¡ç®—ç›¸ä¼¼åº¦
	distance := matrix[len1][len2]
	maxLen := max(len1, len2)
	if maxLen == 0 {
		return 1.0
	}

	return 1.0 - float64(distance)/float64(maxLen)
}

// truncateText æˆªæ–­æ–‡æœ¬ç”¨äºæ—¥å¿—æ˜¾ç¤º
func truncateText(text string, maxLen int) string {
	runes := []rune(text)
	if len(runes) <= maxLen {
		return text
	}
	return string(runes[:maxLen]) + "..."
}

// min è¿”å›ä¸‰ä¸ªæ•´æ•°ä¸­çš„æœ€å°å€¼
func min(a, b, c int) int {
	if a < b {
		if a < c {
			return a
		}
		return c
	}
	if b < c {
		return b
	}
	return c
}

// max è¿”å›ä¸¤ä¸ªæ•´æ•°ä¸­çš„æœ€å¤§å€¼
func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

// recordTranslationRound è®°å½•å•è½®ç¿»è¯‘çš„è¯¦ç»†ç»“æœ
func (bt *BatchTranslator) recordTranslationRound(roundNumber int, roundType string, totalNodes int, nodes []*document.NodeInfo, duration time.Duration) {
	var successNodes []int
	var failedNodes []int
	var failedDetails []*FailedNodeDetail

	for _, node := range nodes {
		if node.Status == document.NodeStatusSuccess {
			successNodes = append(successNodes, node.ID)
		} else {
			failedNodes = append(failedNodes, node.ID)

			// æ”¶é›†å¤±è´¥èŠ‚ç‚¹è¯¦æƒ…ï¼ŒåŒ…æ‹¬æ­¥éª¤ä¿¡æ¯
			errorType, step, stepIndex := extractErrorDetails(node.Error)
			detail := &FailedNodeDetail{
				NodeID:       node.ID,
				OriginalText: truncateText(node.OriginalText, 200),
				Path:         node.Path,
				ErrorType:    errorType,
				ErrorMessage: func() string {
					if node.Error != nil {
						return node.Error.Error()
					}
					return "unknown error"
				}(),
				Step:        step,
				StepIndex:   stepIndex,
				RetryCount:  node.RetryCount,
				FailureTime: time.Now(),
			}
			failedDetails = append(failedDetails, detail)
		}
	}

	roundResult := &TranslationRoundResult{
		RoundNumber:   roundNumber,
		RoundType:     roundType,
		TotalNodes:    totalNodes,
		SuccessNodes:  successNodes,
		FailedNodes:   failedNodes,
		SuccessCount:  len(successNodes),
		FailedCount:   len(failedNodes),
		Duration:      duration,
		FailedDetails: failedDetails,
	}

	bt.mu.Lock()
	bt.translationRounds = append(bt.translationRounds, roundResult)
	bt.mu.Unlock()

	bt.logger.Info("recorded translation round",
		zap.Int("roundNumber", roundNumber),
		zap.String("roundType", roundType),
		zap.Int("totalNodes", totalNodes),
		zap.Int("successCount", len(successNodes)),
		zap.Int("failedCount", len(failedNodes)),
		zap.Duration("duration", duration))
}

// GetDetailedTranslationSummary è·å–è¯¦ç»†çš„ç¿»è¯‘æ±‡æ€»
func (bt *BatchTranslator) GetDetailedTranslationSummary(nodes []*document.NodeInfo) *DetailedTranslationSummary {
	bt.mu.Lock()
	defer bt.mu.Unlock()

	// ç»Ÿè®¡æœ€ç»ˆç»“æœ
	finalSuccess := 0
	finalFailed := 0
	var finalFailedNodes []*FailedNodeDetail

	for _, node := range nodes {
		if node.Status == document.NodeStatusSuccess {
			finalSuccess++
		} else {
			finalFailed++
			errorType, step, stepIndex := extractErrorDetails(node.Error)
			detail := &FailedNodeDetail{
				NodeID:       node.ID,
				OriginalText: truncateText(node.OriginalText, 200),
				Path:         node.Path,
				ErrorType:    errorType,
				ErrorMessage: func() string {
					if node.Error != nil {
						return node.Error.Error()
					}
					return "unknown error"
				}(),
				Step:        step,
				StepIndex:   stepIndex,
				RetryCount:  node.RetryCount,
				FailureTime: time.Now(),
			}
			finalFailedNodes = append(finalFailedNodes, detail)
		}
	}

	return &DetailedTranslationSummary{
		TotalNodes:       len(nodes),
		FinalSuccess:     finalSuccess,
		FinalFailed:      finalFailed,
		TotalRounds:      len(bt.translationRounds),
		Rounds:           bt.translationRounds,
		FinalFailedNodes: finalFailedNodes,
	}
}

// isOnlyProtectedContent æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åªåŒ…å«ä¿æŠ¤æ ‡è®°å’Œç©ºç™½å­—ç¬¦
func (bt *BatchTranslator) isOnlyProtectedContent(text string, preserveManager *translation.PreserveManager) bool {
	// ç§»é™¤æ‰€æœ‰ä¿æŠ¤æ ‡è®°
	cleanedText := preserveManager.RemoveProtectionMarkers(text)
	
	// å¦‚æœç§»é™¤ä¿æŠ¤æ ‡è®°ååªå‰©ä¸‹ç©ºç™½å­—ç¬¦ï¼Œåˆ™è®¤ä¸ºæ˜¯çº¯ä¿æŠ¤å†…å®¹
	trimmedText := strings.TrimSpace(cleanedText)
	return trimmedText == ""
}
