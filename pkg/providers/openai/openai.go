package openai

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"

	"github.com/nerdneilsfield/go-translator-agent/pkg/providers"
	"github.com/nerdneilsfield/go-translator-agent/pkg/providers/retry"
)

// Config OpenAIé…ç½®
type Config struct {
	providers.BaseConfig
	Model       string            `json:"model"`
	Temperature float32           `json:"temperature"`
	MaxTokens   int               `json:"max_tokens"`
	RetryConfig retry.RetryConfig `json:"retry_config"`
}

// DefaultConfig è¿”å›é»˜è®¤é…ç½®
func DefaultConfig() Config {
	return Config{
		BaseConfig:  providers.DefaultConfig(),
		Model:       "gpt-3.5-turbo",
		Temperature: 0.3,
		MaxTokens:   4096,
		RetryConfig: retry.DefaultRetryConfig(),
	}
}

// Provider OpenAIæä¾›å•†
type Provider struct {
	config      Config
	httpClient  *http.Client
	retryClient *retry.RetryableHTTPClient
}

// New åˆ›å»ºæ–°çš„OpenAIæä¾›å•†
func New(config Config) *Provider {
	if config.APIEndpoint == "" {
		config.APIEndpoint = "https://api.openai.com/v1"
	}

	httpClient := &http.Client{
		Timeout: config.Timeout,
	}

	// åˆ›å»ºç½‘ç»œé‡è¯•å™¨
	networkRetrier := retry.NewNetworkRetrier(config.RetryConfig)
	retryClient := networkRetrier.WrapHTTPClient(httpClient)

	return &Provider{
		config:      config,
		httpClient:  httpClient,
		retryClient: retryClient,
	}
}

// Configure é…ç½®æä¾›å•†
func (p *Provider) Configure(config interface{}) error {
	cfg, ok := config.(Config)
	if !ok {
		return fmt.Errorf("invalid config type: expected Config")
	}
	p.config = cfg
	return nil
}

// Translate æ‰§è¡Œç¿»è¯‘
func (p *Provider) Translate(ctx context.Context, req *providers.ProviderRequest) (*providers.ProviderResponse, error) {
	// æ£€æŸ¥æ˜¯å¦æœ‰é¢„æ„å»ºçš„å®Œæ•´æç¤ºè¯ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
	var messages []Message
	
	// å¦‚æœTextçœ‹èµ·æ¥åƒæ˜¯å®Œæ•´çš„æç¤ºè¯ï¼ˆåŒ…å«ç³»ç»ŸæŒ‡ä»¤ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
	if contains, systemPart, userPart := p.parseFullPrompt(req.Text); contains {
		messages = []Message{
			{
				Role:    "system",
				Content: systemPart,
			},
			{
				Role:    "user", 
				Content: userPart,
			},
		}
	} else {
		// å¦åˆ™ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼æ„å»º
		messages = []Message{
			{
				Role:    "system",
				Content: "You are a professional translator. Translate accurately while preserving the original meaning and tone.",
			},
			{
				Role: "user",
				Content: fmt.Sprintf("Translate the following text from %s to %s:\n\n%s",
					req.SourceLanguage, req.TargetLanguage, req.Text),
			},
		}

		// å¦‚æœæœ‰é¢å¤–çš„ä¸Šä¸‹æ–‡æˆ–æŒ‡ä»¤
		if req.Metadata != nil {
			if instruction, ok := req.Metadata["instruction"]; ok {
				if instructionStr, ok := instruction.(string); ok {
					messages[0].Content += "\n\n" + instructionStr
				}
			}
		}
	}

	// åˆ›å»ºè¯·æ±‚
	chatReq := ChatRequest{
		Model:       p.config.Model,
		Messages:    messages,
		Temperature: p.config.Temperature,
		MaxTokens:   p.config.MaxTokens,
		Stream:      false, // æ˜ç¡®ç¦ç”¨æµå¼ä¼ è¾“ï¼Œç‰¹åˆ«æ˜¯å¯¹æ¨ç†æ¨¡å‹
	}

	// æ‰§è¡Œè¯·æ±‚
	resp, err := p.chat(ctx, chatReq)
	if err != nil {
		return nil, err
	}

	// è¿”å›å“åº”
	return &providers.ProviderResponse{
		Text:      resp.Choices[0].Message.Content,
		TokensIn:  resp.Usage.PromptTokens,
		TokensOut: resp.Usage.CompletionTokens,
		Metadata: map[string]interface{}{
			"model":         resp.Model,
			"finish_reason": resp.Choices[0].FinishReason,
			"id":            resp.ID,
		},
	}, nil
}

// GetName è·å–æä¾›å•†åç§°
func (p *Provider) GetName() string {
	return "openai"
}

// SupportsSteps æ”¯æŒå¤šæ­¥éª¤ç¿»è¯‘
func (p *Provider) SupportsSteps() bool {
	return true
}

// GetCapabilities è·å–æä¾›å•†èƒ½åŠ›
func (p *Provider) GetCapabilities() providers.Capabilities {
	return providers.Capabilities{
		SupportedLanguages: []providers.Language{
			{Code: "en", Name: "English"},
			{Code: "zh", Name: "Chinese"},
			{Code: "ja", Name: "Japanese"},
			{Code: "ko", Name: "Korean"},
			{Code: "es", Name: "Spanish"},
			{Code: "fr", Name: "French"},
			{Code: "de", Name: "German"},
			{Code: "ru", Name: "Russian"},
			{Code: "pt", Name: "Portuguese"},
			{Code: "it", Name: "Italian"},
			// OpenAIæ”¯æŒæ›´å¤šè¯­è¨€ï¼Œè¿™é‡Œåªåˆ—å‡ºä¸»è¦çš„
		},
		MaxTextLength:      8000, // å–å†³äºæ¨¡å‹
		SupportsBatch:      false,
		SupportsFormatting: true,
		RequiresAPIKey:     true,
		RateLimit: &providers.RateLimit{
			RequestsPerMinute: 60, // å–å†³äºè´¦æˆ·ç±»å‹
		},
	}
}

// HealthCheck å¥åº·æ£€æŸ¥
func (p *Provider) HealthCheck(ctx context.Context) error {
	// å‘é€ä¸€ä¸ªç®€å•çš„èŠå¤©è¯·æ±‚
	req := ChatRequest{
		Model: p.config.Model,
		Messages: []Message{
			{Role: "user", Content: "Hello"},
		},
		MaxTokens: 10,
	}

	_, err := p.chat(ctx, req)
	return err
}

// chat æ‰§è¡ŒèŠå¤©è¯·æ±‚
func (p *Provider) chat(ctx context.Context, req ChatRequest) (*ChatResponse, error) {
	// ç¼–ç è¯·æ±‚
	body, err := json.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	// åˆ›å»ºHTTPè¯·æ±‚
	httpReq, err := http.NewRequestWithContext(ctx, "POST",
		p.config.APIEndpoint+"/chat/completions", bytes.NewReader(body))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	// è®¾ç½®å¤´éƒ¨
	httpReq.Header.Set("Content-Type", "application/json")
	httpReq.Header.Set("Authorization", "Bearer "+p.config.APIKey)
	for k, v := range p.config.Headers {
		httpReq.Header.Set(k, v)
	}

	// æ‰§è¡Œè¯·æ±‚ï¼Œä½¿ç”¨æ™ºèƒ½é‡è¯•
	resp, err := p.retryClient.Do(httpReq)
	if err != nil {
		return nil, fmt.Errorf("failed to execute request: %w", err)
	}

	// æ£€æŸ¥HTTPçŠ¶æ€ç 
	if resp.StatusCode < 200 || resp.StatusCode >= 300 {
		// è¯»å–é”™è¯¯å“åº”
		errBody, _ := io.ReadAll(resp.Body)
		resp.Body.Close()

		// è§£æé”™è¯¯
		var apiErr APIError
		if json.Unmarshal(errBody, &apiErr) == nil {
			return nil, &apiErr
		}
		return nil, fmt.Errorf("API error: %s", resp.Status)
	}

	defer resp.Body.Close()

	// è§£æå“åº”
	var chatResp ChatResponse
	if err := json.NewDecoder(resp.Body).Decode(&chatResp); err != nil {
		return nil, fmt.Errorf("failed to decode response: %w", err)
	}

	return &chatResp, nil
}

// parseFullPrompt è§£æå®Œæ•´æç¤ºè¯ï¼Œåˆ†ç¦»ç³»ç»ŸæŒ‡ä»¤å’Œç”¨æˆ·å†…å®¹
func (p *Provider) parseFullPrompt(text string) (bool, string, string) {
	// æ£€æŸ¥æ˜¯å¦åŒ…å«ç³»ç»ŸæŒ‡ä»¤å’Œç¿»è¯‘æŒ‡ä»¤çš„å…³é”®æ ‡è¯†
	if strings.Contains(text, "You are a professional translator") && 
	   strings.Contains(text, "ğŸš¨ CRITICAL INSTRUCTION") {
		
		// æŒ‰åŒæ¢è¡Œåˆ†å‰²ç³»ç»ŸæŒ‡ä»¤å’Œç”¨æˆ·å†…å®¹
		parts := strings.SplitN(text, "\n\n", 2)
		if len(parts) == 2 {
			return true, parts[0], parts[1]
		}
	}
	
	return false, "", ""
}

// Message èŠå¤©æ¶ˆæ¯
type Message struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// ChatRequest èŠå¤©è¯·æ±‚
type ChatRequest struct {
	Model       string    `json:"model"`
	Messages    []Message `json:"messages"`
	Temperature float32   `json:"temperature,omitempty"`
	MaxTokens   int       `json:"max_tokens,omitempty"`
	Stream      bool      `json:"stream,omitempty"`
}

// ChatResponse èŠå¤©å“åº”
type ChatResponse struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	Model   string `json:"model"`
	Choices []struct {
		Index        int     `json:"index"`
		Message      Message `json:"message"`
		FinishReason string  `json:"finish_reason"`
	} `json:"choices"`
	Usage struct {
		PromptTokens     int `json:"prompt_tokens"`
		CompletionTokens int `json:"completion_tokens"`
		TotalTokens      int `json:"total_tokens"`
	} `json:"usage"`
}

// APIError APIé”™è¯¯
type APIError struct {
	ErrorInfo struct {
		Message string `json:"message"`
		Type    string `json:"type"`
		Code    string `json:"code"`
	} `json:"error"`
}

func (e *APIError) Error() string {
	return e.ErrorInfo.Message
}

// å®ç° LLMClient æ¥å£ä»¥æ”¯æŒä¸‰æ­¥ç¿»è¯‘
// type LLMClient struct {
// 	provider *Provider
// }
//
// // NewLLMClient åˆ›å»ºLLMClient
// func NewLLMClient(config Config) *LLMClient {
// 	return &LLMClient{
// 		provider: New(config),
// 	}
// }
//
// // Chat å®ç° translation.LLMClient æ¥å£
// func (c *LLMClient) Chat(ctx context.Context, req *translation.ChatRequest) (*translation.ChatResponse, error) {
// 	// è½¬æ¢æ¶ˆæ¯æ ¼å¼
// 	messages := make([]Message, len(req.Messages))
// 	for i, msg := range req.Messages {
// 		messages[i] = Message{
// 			Role:    msg.Role,
// 			Content: msg.Content,
// 		}
// 	}
//
// 	// åˆ›å»ºè¯·æ±‚
// 	chatReq := ChatRequest{
// 		Model:       req.Model,
// 		Messages:    messages,
// 		Temperature: req.Temperature,
// 		MaxTokens:   req.MaxTokens,
// 	}
//
// 	if chatReq.Model == "" {
// 		chatReq.Model = c.provider.config.Model
// 	}
//
// 	// æ‰§è¡Œè¯·æ±‚
// 	resp, err := c.provider.chat(ctx, chatReq)
// 	if err != nil {
// 		return nil, err
// 	}
//
// 	// è½¬æ¢å“åº”
// 	return &translation.ChatResponse{
// 		Message: translation.ChatMessage{
// 			Role:    resp.Choices[0].Message.Role,
// 			Content: resp.Choices[0].Message.Content,
// 		},
// 		Model:     resp.Model,
// 		TokensIn:  resp.Usage.PromptTokens,
// 		TokensOut: resp.Usage.CompletionTokens,
// 	}, nil
// }
//
// // Complete å®ç° translation.LLMClient æ¥å£
// func (c *LLMClient) Complete(ctx context.Context, req *translation.CompletionRequest) (*translation.CompletionResponse, error) {
// 	// å°†completionè¯·æ±‚è½¬æ¢ä¸ºchatè¯·æ±‚
// 	chatReq := &translation.ChatRequest{
// 		Messages: []translation.ChatMessage{
// 			{
// 				Role:    "user",
// 				Content: req.Prompt,
// 			},
// 		},
// 		Model:       req.Model,
// 		Temperature: req.Temperature,
// 		MaxTokens:   req.MaxTokens,
// 	}
//
// 	resp, err := c.Chat(ctx, chatReq)
// 	if err != nil {
// 		return nil, err
// 	}
//
// 	return &translation.CompletionResponse{
// 		Text:      resp.Message.Content,
// 		Model:     resp.Model,
// 		TokensIn:  resp.TokensIn,
// 		TokensOut: resp.TokensOut,
// 	}, nil
// }
//
// // GetModel è·å–æ¨¡å‹
// func (c *LLMClient) GetModel() string {
// 	return c.provider.config.Model
// }
//
// // HealthCheck å¥åº·æ£€æŸ¥
// func (c *LLMClient) HealthCheck(ctx context.Context) error {
// 	return c.provider.HealthCheck(ctx)
// }
